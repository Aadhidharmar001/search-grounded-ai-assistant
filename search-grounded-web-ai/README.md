ğŸ” Search-Grounded AI Assistant (RAG)

A search-grounded AI assistant that answers user questions using real-time web data, reducing hallucinations by grounding responses in verifiable sources.

This project demonstrates a Retrieval-Augmented Generation (RAG) architecture using Tavily for web search and an LLM for controlled reasoning.

ğŸš€ Features

ğŸ” Real-time web search using Tavily Search API

ğŸ§  RAG architecture (Retrieve â†’ Augment â†’ Generate)

ğŸ’¬ Conversational memory (multi-turn context)

ğŸ“Š Confidence score for each answer

âš ï¸ Uncertainty & assumptions section

ğŸ”— Transparent source citations

ğŸ¤– Suggested follow-up questions (agent-like behavior)

ğŸ¨ Clean, recruiter-friendly UI

ğŸ›¡ï¸ Reduced hallucinations by design

ğŸ§  Architecture Overview
User (Browser)
   â†“
Flask Web App (Server)
   â†“
Tavily Web Search (Retrieval)
   â†“
Context Builder (Augmentation)
   â†“
LLM (Generation)
   â†“
Answer + Sources + Confidence


This system does not rely on the LLMâ€™s internal knowledge alone.
Instead, it grounds every answer in live web data.

ğŸ” Why RAG?

Large Language Models have:

Static training data

Knowledge cutoffs

Finite context windows

By using Retrieval-Augmented Generation, this app:

Fetches fresh, relevant information

Limits hallucinations

Improves trust and explainability

ğŸ› ï¸ Tech Stack

Backend: Python, Flask

Retrieval: Tavily Search API

LLM: OpenRouter (OpenAI-compatible API)

Frontend: HTML, CSS (vanilla)

State: Flask session (chat memory)

No heavy frameworks (LangChain, React) â€” everything is explicit and explainable.

ğŸ“‚ Project Structure
.
â”œâ”€â”€ app.py                # Flask backend
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # UI
â”œâ”€â”€ .env                  # API keys
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the repository
git clone https://github.com/your-username/search-grounded-ai
cd search-grounded-ai

2ï¸âƒ£ Create virtual environment
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add environment variables (.env)
TAVILY_API_KEY=your_tavily_key
OPENROUTER_API_KEY=your_openrouter_key

5ï¸âƒ£ Run the app
python app.py


Open: http://127.0.0.1:5000

ğŸ§ª Example Query

User: Who won yesterdayâ€™s India vs Pakistan cricket match?

AI Answer:

India won by 61 runs

Confidence: High (0.90)

Sources: Economic Times, The Hindu, Indian Express

ğŸ” Security & Safety Notes

LLM outputs plain text only (no HTML rendering)

UI escapes content safely

API keys stored via environment variables

Designed for demo / portfolio use (not production)

ğŸ“Œ What This Project Demonstrates

Practical use of RAG (not just theory)

Controlled LLM reasoning

Explainable AI outputs

End-to-end system design

Real-world AI engineering patterns

ğŸ§© Future Improvements

Deployment (Render / Railway)

Streaming responses

Source sentence highlighting

Feedback loop (thumbs up/down)

Caching frequent queries

ğŸ‘¤ Author

Aadhidharmar T
B.Tech AI & Data Science
Focused on practical ML, RAG systems, and AI product engineering

â­ Final Note

This project focuses on trust, grounding, and explainability, not just generation â€” reflecting how real-world AI systems are built.